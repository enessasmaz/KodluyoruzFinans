{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "NHi-saK3u9Cw"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup \n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "banks = [\"akbank\",\"halkbank\",\"is%20bankasi\",\"yapi%20kredi\",\"vakifbank\",\"garanti\",\"denizbank\"]\n",
    "web_links = {\n",
    "    \"borsa_gundem\":\"https://www.borsagundem.com/ara/{bank}/{i}\",\n",
    "    \"bloomberght\":\"https://www.bloomberght.com/liste/arama/{i}?ara={bank}&baslangic_tarihi=&bitis_tarihi=\",\n",
    "    \"hurriyet\":\"http://bigpara.hurriyet.com.tr/arama/?firstDate=2015-06-01&secondDate=2020-09-28&includeKap=False&page={i}&s={bank}\",\n",
    "    \"finans_gundem\":\"https://www.finansgundem.com/ara/{bank}/{i}\"\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def borsa_gundem(array,bank):\n",
    "    for i in tqdm(range(1,75)):\n",
    "        page = requests.get(web_links[\"borsa_gundem\"].format(bank=bank,i=i))\n",
    "        sp = BeautifulSoup(page.content,\"html.parser\")\n",
    "        liste = sp.find(\"div\",{\"class\":\"srch\"}).find_all(\"li\")\n",
    "        for l in liste: \n",
    "            try:\n",
    "                title = l.strong.text\n",
    "                tarih = l.small.text\n",
    "                tarih = tarih[:tarih.find(\",\")]\n",
    "                content = \"\"\n",
    "                pg = requests.get(l.a.get(\"href\"))\n",
    "                psp = BeautifulSoup(pg.content,\"html.parser\")\n",
    "                for i in list(psp.find(\"div\",{\"class\":\"dtail\"}).find_all(\"p\")[:-2]):\n",
    "                    content += i.text.replace(\"\\xa0\",\" \")\n",
    "                if not content:\n",
    "                    continue\n",
    "                array.append([title,content,tarih,bank])\n",
    "            except Exception as e:\n",
    "                print(l.a.get(\"href\"),\"  \",e)\n",
    "                continue    \n",
    "\n",
    "def bloomberght(array,bank):\n",
    "    adres = \"https://www.bloomberght.com\"\n",
    "    for i in tqdm(range(1,50)):\n",
    "        page = requests.get(web_links[\"bloomberght\"].format(bank=bank,i=i))\n",
    "        sp = BeautifulSoup(page.content,\"html.parser\")\n",
    "        liste = [adres + i.a.get(\"href\") for i in sp.find_all(\"div\",{\"class\":\"box box-12 item\"}) if not \"/video/\" in i.a.get(\"href\")]\n",
    "\n",
    "        for l in liste:\n",
    "            try:\n",
    "                pg = requests.get(l)\n",
    "                psp = BeautifulSoup(pg.content,\"html.parser\")\n",
    "\n",
    "                title = psp.h1.span.text\n",
    "                tarih = psp.find(\"div\",{\"class\":\"news-info\"}).span.time.text\n",
    "                tarih = \" \".join(tarih.split()[:3])\n",
    "                content =\"\"\n",
    "                for i in list(psp.article.find_all(\"p\")):\n",
    "                    content += i.text\n",
    "                array.append([title,content,tarih,bank])\n",
    "            except Exception as e:\n",
    "                print(l, \"  \", e)\n",
    "                \n",
    "def hurriyet(array,bank):\n",
    "    adres = \"http://bigpara.hurriyet.com.tr\"\n",
    "    for i in tqdm(range(1,30)):   \n",
    "        page = requests.get(web_links[\"hurriyet\"].format(bank=bank,i=i))\n",
    "        sp = BeautifulSoup(page.content, \"html.parser\")\n",
    "        liste = sp.find(\"div\",{\"class\":\"aramasonuc\"}).find_all(\"li\")\n",
    "        \n",
    "        for l in liste:\n",
    "            try:\n",
    "                title = l.a.text\n",
    "                icerik = l.find_all(\"a\")[1].text\n",
    "                tarih = l.span.text[1:-1]\n",
    "                link = adres + l.a.get(\"href\")\n",
    "                pg = requests.get(link)\n",
    "                psp = BeautifulSoup(pg.content, \"html.parser\")\n",
    "                content = \"\"\n",
    "                for i in list(psp.find(\"div\",{\"class\",\"tag-content\"}).find_all(\"p\")):\n",
    "                    content += i.text.replace(\"\\xa0\",\" \")\n",
    "\n",
    "                array.append([title,content,tarih,bank])\n",
    "            except:\n",
    "                print(link)\n",
    "                continue\n",
    "\n",
    "\n",
    "def finans_gundem(array,bank):\n",
    "    for i in tqdm(range(1,75)):\n",
    "        page = requests.get(web_links[\"finans_gundem\"].format(bank=bank,i=i))\n",
    "        sp = BeautifulSoup(page.content,\"html.parser\")\n",
    "        liste = sp.find(\"div\",{\"class\":\"srch\"}).find_all(\"li\")\n",
    "        for l in liste: \n",
    "            try:\n",
    "                title = l.strong.text\n",
    "                tarih = l.small.text\n",
    "                tarih = tarih[:tarih.find(\",\")]\n",
    "                content = \"\"\n",
    "                pg = requests.get(l.a.get(\"href\"))\n",
    "                psp = BeautifulSoup(pg.content,\"html.parser\")\n",
    "                for i in list(psp.find(\"div\",{\"class\":\"dtail\"}).find_all(\"p\")[:-2]):\n",
    "                    content += i.text.replace(\"\\xa0\",\" \")\n",
    "                if not content:\n",
    "                    continue\n",
    "                array.append([title,content,tarih,bank])\n",
    "            except Exception as e:\n",
    "                print(l.a.get(\"href\"),\"  \",e)\n",
    "                continue    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\"title\",\"content\",\"date\",\"bank\"]\n",
    "\n",
    "array = []\n",
    "for bank in banks:\n",
    "    borsa_gundem(array,bank)\n",
    "    bloomberght(array,bank)    \n",
    "    hurriyet(array,bank)    \n",
    "    finans_gundem(array,bank)\n",
    "    data = pd.DataFrame(data=array,columns=column_names)\n",
    "    data.to_csv(\"banks.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "news_scraping.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
